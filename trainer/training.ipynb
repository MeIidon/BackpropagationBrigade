{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "heSLeiKApG55"
      },
      "outputs": [],
      "source": [
        "# Installing kaggle to download the dataset.\n",
        "!pip install kaggle\n",
        "# Installing wandb for tracking the project.\n",
        "!pip install wandb\n",
        "# Installing h5py for loading the weights.\n",
        "!pip install h5py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import wandb\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import datasets, layers, models, callbacks, applications, optimizers, saving\n",
        "from wandb.keras import WandbCallback\n",
        "from getpass import getpass\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix"
      ],
      "metadata": {
        "id": "pPmq8wVj8gpD"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "tlCfhA-_s-73"
      },
      "outputs": [],
      "source": [
        "# We need kaggle credentials which needs to be stored in ~/.kaggle/kaggle.json\n",
        "!mkdir ~/.kaggle\n",
        "!touch ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XPP0_iXQqngd"
      },
      "outputs": [],
      "source": [
        "# Reading in the contents of user's kaggle.json.\n",
        "kaggle_secret = getpass('Enter the content of your kaggle.json: ')\n",
        "\n",
        "# Saving into the previously created file.\n",
        "with open('/root/.kaggle/kaggle.json', \"w\") as f:\n",
        "  f.write(kaggle_secret)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SnGlWGcv73Dv"
      },
      "outputs": [],
      "source": [
        "!wandb login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nt5GbDF5sHy_"
      },
      "outputs": [],
      "source": [
        "# Downloading and unzipping the training dataset.\n",
        "!kaggle competitions download -c tpu-getting-started\n",
        "!unzip tpu-getting-started.zip -d data\n",
        "!rm tpu-getting-started.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "hwHaiyUWt_mz"
      },
      "outputs": [],
      "source": [
        "# Image related constants.\n",
        "IMAGE_SIZE = [224, 224]\n",
        "NUM_OF_CLASSES = 104\n",
        "\n",
        "# Paths to the training, validation and test datasets.\n",
        "DATASET_PATH = \"data\"\n",
        "PATH = DATASET_PATH + f\"/tfrecords-jpeg-{IMAGE_SIZE[0]}x{IMAGE_SIZE[1]}\"\n",
        "TRAINING_FILENAMES = tf.io.gfile.glob(PATH + \"/train/*.tfrec\")\n",
        "VALIDATION_FILENAMES = tf.io.gfile.glob(PATH + \"/val/*.tfrec\")\n",
        "TEST_FILENAMES = tf.io.gfile.glob(PATH + \"/test/*.tfrec\")\n",
        "\n",
        "# Flower classes corresponding to each id (0..103).\n",
        "CLASSES = [\n",
        "    \"pink primrose\",  # 0\n",
        "    \"hard-leaved pocket orchid\",  # 1\n",
        "    \"canterbury bells\",  # 2\n",
        "    \"sweet pea\",  # 3\n",
        "    \"wild geranium\",  # 4\n",
        "    \"tiger lily\",  # 5\n",
        "    \"moon orchid\",  # 6\n",
        "    \"bird of paradise\",  # 7\n",
        "    \"monkshood\",  # 8\n",
        "    \"globe thistle\",  # 9\n",
        "    \"snapdragon\",  # 10\n",
        "    \"colt's foot\",  # 11\n",
        "    \"king protea\",  # 12\n",
        "    \"spear thistle\",  # 13\n",
        "    \"yellow iris\",  # 14\n",
        "    \"globe-flower\",  # 15\n",
        "    \"purple coneflower\",  # 16\n",
        "    \"peruvian lily\",  # 17\n",
        "    \"balloon flower\",  # 18\n",
        "    \"giant white arum lily\",  # 19\n",
        "    \"fire lily\",  # 20\n",
        "    \"pincushion flower\",  # 21\n",
        "    \"fritillary\",  # 22\n",
        "    \"red ginger\",  # 23\n",
        "    \"grape hyacinth\",  # 24\n",
        "    \"corn poppy\",  # 25\n",
        "    \"prince of wales feathers\",  # 26\n",
        "    \"stemless gentian\",  # 27\n",
        "    \"artichoke\",  # 28\n",
        "    \"sweet william\",  # 29\n",
        "    \"carnation\",  # 30\n",
        "    \"garden phlox\",  # 31\n",
        "    \"love in the mist\",  # 32\n",
        "    \"cosmos\",  # 33\n",
        "    \"alpine sea holly\",  # 34\n",
        "    \"ruby-lipped cattleya\",  # 35\n",
        "    \"cape flower\",  # 36\n",
        "    \"great masterwort\",  # 37\n",
        "    \"siam tulip\",  # 38\n",
        "    \"lenten rose\",  # 39\n",
        "    \"barberton daisy\",  # 40\n",
        "    \"daffodil\",  # 41\n",
        "    \"sword lily\",  # 42\n",
        "    \"poinsettia\",  # 43\n",
        "    \"bolero deep blue\",  # 44\n",
        "    \"wallflower\",  # 45\n",
        "    \"marigold\",  # 46\n",
        "    \"buttercup\",  # 47\n",
        "    \"daisy\",  # 48\n",
        "    \"common dandelion\",  # 49\n",
        "    \"petunia\",  # 50\n",
        "    \"wild pansy\",  # 51\n",
        "    \"primula\",  # 52\n",
        "    \"sunflower\",  # 53\n",
        "    \"lilac hibiscus\",  # 54\n",
        "    \"bishop of llandaff\",  # 55\n",
        "    \"gaura\",  # 56\n",
        "    \"geranium\",  # 57\n",
        "    \"orange dahlia\",  # 58\n",
        "    \"pink-yellow dahlia\",  # 59\n",
        "    \"cautleya spicata\",  # 60\n",
        "    \"japanese anemone\",  # 61\n",
        "    \"black-eyed susan\",  # 62\n",
        "    \"silverbush\",  # 63\n",
        "    \"californian poppy\",  # 64\n",
        "    \"osteospermum\",  # 65\n",
        "    \"spring crocus\",  # 66\n",
        "    \"iris\",  # 67\n",
        "    \"windflower\",  # 68\n",
        "    \"tree poppy\",  # 69\n",
        "    \"gazania\",  # 70\n",
        "    \"azalea\",  # 71\n",
        "    \"water lily\",  # 72\n",
        "    \"rose\",  # 73\n",
        "    \"thorn apple\",  # 74\n",
        "    \"morning glory\",  # 75\n",
        "    \"passion flower\",  # 76\n",
        "    \"lotus\",  # 77\n",
        "    \"toad lily\",  # 78\n",
        "    \"anthurium\",  # 79\n",
        "    \"frangipani\",  # 80\n",
        "    \"clematis\",  # 81\n",
        "    \"hibiscus\",  # 82\n",
        "    \"columbine\",  # 83\n",
        "    \"desert-rose\",  # 84\n",
        "    \"tree mallow\",  # 85\n",
        "    \"magnolia\",  # 86\n",
        "    \"cyclamen \",  # 87\n",
        "    \"watercress\",  # 88\n",
        "    \"canna lily\",  # 89\n",
        "    \"hippeastrum \",  # 90\n",
        "    \"bee balm\",  # 91\n",
        "    \"pink quill\",  # 92\n",
        "    \"foxglove\",  # 93\n",
        "    \"bougainvillea\",  # 94\n",
        "    \"camellia\",  # 95\n",
        "    \"mallow\",  # 96\n",
        "    \"mexican petunia\",  # 97\n",
        "    \"bromelia\",  # 98\n",
        "    \"blanket flower\",  # 99\n",
        "    \"trumpet creeper\",  # 100\n",
        "    \"blackberry lily\",  # 101\n",
        "    \"common tulip\",  # 102\n",
        "    \"wild rose\",  # 103\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "DI-dXAxuxm9o"
      },
      "outputs": [],
      "source": [
        "# This function converts the raw image data to a [IMAGE_SIZE, 3] shaped array\n",
        "# containing the normalized color intensity values for all channels.\n",
        "def decode_image(image_data):\n",
        "  # Extracting the image from the dataset.\n",
        "  image = tf.image.decode_jpeg(image_data, channels=3)\n",
        "  # Normalizing the color intensity values.\n",
        "  image = (\n",
        "      tf.cast(image, tf.float32) / 255.0\n",
        "  )\n",
        "  # Reshaping for 3 channels.\n",
        "  image = tf.reshape(image, [*IMAGE_SIZE, 3])\n",
        "  return image\n",
        "\n",
        "\n",
        "# This function takes a raw labelled tfrecord and converts it to decoded image data\n",
        "# and one hot encoded label.\n",
        "def read_labelled_tfrecord(example):\n",
        "  LABELLED_TFREC_FORMAT = {\n",
        "    \"image\": tf.io.FixedLenFeature([], tf.string),\n",
        "    \"class\": tf.io.FixedLenFeature([], tf.int64),\n",
        "  }\n",
        "  # Converting the raw data to a python dictionary with LABELLED_TFREC_FORMAT.\n",
        "  example = tf.io.parse_single_example(example, LABELLED_TFREC_FORMAT)\n",
        "  # Decoding the image.\n",
        "  image = decode_image(example[\"image\"])\n",
        "  # One-hot encode the label of the image.\n",
        "  label = tf.cast(example[\"class\"], tf.int32)\n",
        "  one_hot = tf.one_hot(label, NUM_OF_CLASSES)\n",
        "  return image, one_hot\n",
        "\n",
        "\n",
        "# This function takes a raw unlabelled tfrecord and converts it to decoded image data\n",
        "# and the id of the test image.\n",
        "def read_unlabelled_tfrecord(example):\n",
        "  UNLABELLED_TFREC_FORMAT = {\n",
        "    \"image\": tf.io.FixedLenFeature([], tf.string),\n",
        "    \"id\": tf.io.FixedLenFeature([], tf.string),\n",
        "  }\n",
        "  # Converting raw data to a python dictionary with UNLABELLED_TFREC_FORMAT.\n",
        "  example = tf.io.parse_single_example(example, UNLABELLED_TFREC_FORMAT)\n",
        "  # Decoding the image.\n",
        "  image = decode_image(example[\"image\"])\n",
        "  id_num = example[\"id\"]\n",
        "  return image, id_num\n",
        "\n",
        "\n",
        "# This function takes several filenames (tfrecords) and creates a tensorflow\n",
        "# dataset from them.\n",
        "def load_dataset(filenames, labelled=True, ordered=False):\n",
        "  # The order of the images doesn't matter so we are turning on ignore_order\n",
        "  # this results in faster loading times.\n",
        "  ignore_order = tf.data.Options()\n",
        "  if not ordered:\n",
        "    ignore_order.experimental_deterministic = False\n",
        "\n",
        "  # Creating the dataset. We are using parallel read option because obviously\n",
        "  # it results in faster loading times.\n",
        "  dataset = tf.data.TFRecordDataset(\n",
        "    filenames, num_parallel_reads=tf.data.experimental.AUTOTUNE\n",
        "  )\n",
        "  dataset = dataset.with_options(ignore_order)\n",
        "  # The final element of the pipeline is taking the raw tfrecord\n",
        "  # and converting it to labelled on unlabelled input data with the upper functions.\n",
        "  dataset = dataset.map(\n",
        "    read_labelled_tfrecord if labelled else read_unlabelled_tfrecord,\n",
        "    num_parallel_calls=tf.data.experimental.AUTOTUNE,\n",
        "  )\n",
        "  return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "boA0dEsByty-"
      },
      "outputs": [],
      "source": [
        "# This function creates the training dataset.\n",
        "# repeat will be used, this will make sure that after reaching the end record\n",
        "# we go back to the first.\n",
        "# BATCH_SIZE will be used.\n",
        "# We will prefetch 1 batch for accellerating the reading process.\n",
        "def get_training_dataset(batch_size):\n",
        "  dataset = load_dataset(TRAINING_FILENAMES, labelled=True)\n",
        "  dataset = dataset.repeat()\n",
        "  dataset = dataset.batch(batch_size)\n",
        "  dataset = dataset.prefetch(1)\n",
        "  return dataset\n",
        "\n",
        "\n",
        "# This function creates the validation dataset.\n",
        "# BATCH_SIZE will be used.\n",
        "# We will prefetch 1 batch for accellerating the reading process.\n",
        "def get_validation_dataset(batch_size, ordered=False):\n",
        "  dataset = load_dataset(VALIDATION_FILENAMES, labelled=True, ordered=ordered)\n",
        "  dataset = dataset.batch(batch_size)\n",
        "  dataset = dataset.prefetch(1)\n",
        "  return dataset\n",
        "\n",
        "\n",
        "# This function creates the test dataset.\n",
        "# BATCH_SIZE will be used.\n",
        "# We will prefetch 1 batch for accellerating the reading process.\n",
        "def get_test_dataset(batch_size, ordered=False):\n",
        "  dataset = load_dataset(TEST_FILENAMES, labelled=False, ordered=ordered)\n",
        "  dataset = dataset.batch(batch_size)\n",
        "  dataset = dataset.prefetch(1)\n",
        "  return dataset\n",
        "\n",
        "\n",
        "# This function counts the number of tfrecords in a dataset.\n",
        "def count_data_items(filenames):\n",
        "  n = [\n",
        "    int(re.compile(r\"-(\\d*)\\.\").search(filename).group(1))\n",
        "    for filename in filenames\n",
        "  ]\n",
        "  return np.sum(n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "UQFiJq8dzhZn"
      },
      "outputs": [],
      "source": [
        "# This will be used to calculate the number of batches needed to go through\n",
        "# all the dataset in an epoch.\n",
        "num_train_images = count_data_items(TRAINING_FILENAMES)\n",
        "num_validation_images = count_data_items(VALIDATION_FILENAMES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4lKwPTy1M8t"
      },
      "outputs": [],
      "source": [
        "sweep_config = {\n",
        "    'method': 'bayes',\n",
        "    'name': 'hyperopt',\n",
        "    'metric': {\n",
        "        'goal': 'maximize',\n",
        "        'name': 'val_accuracy'\n",
        "    },\n",
        "    'parameters': {\n",
        "        'epochs': {\n",
        "            'value': 20\n",
        "        },\n",
        "        'batch_size': {\n",
        "            'values': [32, 64, 128]\n",
        "        },\n",
        "        'h_units_1': {\n",
        "            'values': np.arange(512, 2048, 128).tolist()\n",
        "        },\n",
        "        'h_units_2': {\n",
        "            'values': np.arange(256, 1024, 64).tolist()\n",
        "        },\n",
        "        'h_units_3': {\n",
        "            'values': np.arange(128, 512, 32).tolist()\n",
        "        },\n",
        "        'dropout': {\n",
        "            'values': [0.1, 0.3, 0.5, 0.6]\n",
        "        },\n",
        "        'optimizer': {\n",
        "           'values': ['adam', 'sgd']\n",
        "        },\n",
        "        'learning_rate': {\n",
        "            'min': 0.0001,\n",
        "            'max': 0.1\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "def get_optimizer(learning_rate, optimizer_str):\n",
        "  if optimizer_str.lower() == 'adam':\n",
        "      return optimizers.Adam(learning_rate=learning_rate)\n",
        "  elif optimizer_str.lower() == 'sgd':\n",
        "      return optimizers.SGD(learning_rate=learning_rate, momentum=0.1)\n",
        "\n",
        "def get_model(config):\n",
        "  # Setting seed for being able to reproduce results.\n",
        "  tf.random.set_seed(42)\n",
        "\n",
        "  # Using Transfer Learning technique for this project.\n",
        "  # InceptionV3 pretrained model will be used.\n",
        "  pre_trained_model = applications.InceptionV3(input_shape=(*IMAGE_SIZE, 3), include_top=False, weights='imagenet')\n",
        "\n",
        "  # Freezing the weights of the model.\n",
        "  for layer in pre_trained_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "  # Adding our own model on top of InceptionV3.\n",
        "  x = pre_trained_model.output\n",
        "\n",
        "  # Using pooling to decrease dimension.\n",
        "  x = layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "  # Putting 3 hidden layers with optimized size.\n",
        "  for h_unit in [config['h_units_1'], config['h_units_2'], config['h_units_3']]:\n",
        "    x = layers.Dense(h_unit, activation='relu')(x)\n",
        "    x = layers.Dropout(config['dropout'])(x)\n",
        "\n",
        "  # The output will be a probability distribution of classes.\n",
        "  x = layers.Dense(NUM_OF_CLASSES, activation='softmax')(x)\n",
        "\n",
        "  # Creating and the final model from the pretrained model and our own model.\n",
        "  model = models.Model(pre_trained_model.input, x)\n",
        "\n",
        "  # Creating the optimizer.\n",
        "  optimizer = get_optimizer(config['learning_rate'], config['optimizer'])\n",
        "\n",
        "  # Compiling the final model.\n",
        "  # Using categorical crossentropy loss function because its a classification problem.\n",
        "  model.compile(\n",
        "      optimizer=optimizer,\n",
        "      loss='categorical_crossentropy',\n",
        "      metrics=['accuracy']\n",
        "  )\n",
        "  return model\n",
        "\n",
        "def sweep_train(config_defaults=None):\n",
        "  with wandb.init(config=config_defaults):\n",
        "    # Getting the train and validation datasets.\n",
        "    training_dataset = get_training_dataset(wandb.config.batch_size)\n",
        "    validation_dataset = get_validation_dataset(wandb.config.batch_size)\n",
        "\n",
        "    # Creating the model from the config values.\n",
        "    model = get_model(wandb.config)\n",
        "\n",
        "    # Training the model.\n",
        "    model.fit(\n",
        "        training_dataset,\n",
        "        validation_data=validation_dataset,\n",
        "        epochs=wandb.config.epochs,\n",
        "        steps_per_epoch=num_train_images / wandb.config.batch_size,\n",
        "        callbacks=[\n",
        "            WandbCallback(),\n",
        "            callbacks.EarlyStopping(monitor='val_accuracy', patience=4, verbose=1)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "sweep_id = wandb.sweep(sweep_config, project=\"flower_classification\")\n",
        "wandb.agent(sweep_id, function=sweep_train, count=10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the sweep url where the hyperparameter-optimization happened.\n",
        "sweep_url = getpass('Enter the url of your sweep: ')\n",
        "\n",
        "# Getting the sweep from wandb api.\n",
        "api = wandb.Api()\n",
        "sweep = api.sweep(sweep_url)\n",
        "\n",
        "# Getting the best hyperparameter configuration for the final training.\n",
        "best_run = sweep.best_run()\n",
        "best_configuration = best_run.config\n",
        "\n",
        "# Creating the model from the best configuration.\n",
        "model = get_model(best_configuration)\n",
        "\n",
        "# Getting the datasets from the configuration's batch size.\n",
        "training_dataset = get_training_dataset(best_configuration['batch_size'])\n",
        "validation_dataset = get_validation_dataset(best_configuration['batch_size'])\n",
        "\n",
        "# Training the model.\n",
        "history = model.fit(\n",
        "    training_dataset,\n",
        "    validation_data=validation_dataset,\n",
        "    epochs=100,\n",
        "    steps_per_epoch=num_train_images / best_configuration['batch_size'],\n",
        "    callbacks=[\n",
        "        callbacks.ModelCheckpoint(filepath='model', monitor='val_accuracy', save_best_only=True)\n",
        "        callbacks.EarlyStopping(monitor='val_accuracy', patience=10, verbose=1)\n",
        "    ])"
      ],
      "metadata": {
        "id": "Pf-Kdj1c7U1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This function displays the training and validation curves from the history data.\n",
        "def display_training_curves(training, validation, title, subplot):\n",
        "  if subplot % 10 == 1:\n",
        "    plt.subplots(figsize=(10, 10), facecolor=\"#F0F0F0\")\n",
        "    plt.tight_layout()\n",
        "  ax = plt.subplot(subplot)\n",
        "  ax.set_facecolor(\"#F8F8F8\")\n",
        "  ax.plot(training)\n",
        "  ax.plot(validation)\n",
        "  ax.set_title(\"model \" + title)\n",
        "  ax.set_ylabel(title)\n",
        "  ax.set_xlabel(\"epoch\")\n",
        "  ax.legend([\"train\", \"valid.\"])\n",
        "\n",
        "# This function displays the confusion matrix.\n",
        "def display_confusion_matrix(cmat, score, precision, recall):\n",
        "  plt.figure(figsize=(15, 15))\n",
        "  ax = plt.gca()\n",
        "  ax.matshow(cmat, cmap=\"Reds\")\n",
        "  ax.set_xticks(range(len(CLASSES)))\n",
        "  ax.set_xticklabels(CLASSES, fontdict={\"fontsize\": 7})\n",
        "  plt.setp(ax.get_xticklabels(), rotation=45, ha=\"left\", rotation_mode=\"anchor\")\n",
        "  ax.set_yticks(range(len(CLASSES)))\n",
        "  ax.set_yticklabels(CLASSES, fontdict={\"fontsize\": 7})\n",
        "  plt.setp(ax.get_yticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
        "  title = \"\"\n",
        "  if score is not None:\n",
        "    title += \"f1 = {:.3f} \".format(score)\n",
        "  if precision is not None:\n",
        "    title += \"\\nprecision = {:.3f} \".format(precision)\n",
        "  if recall is not None:\n",
        "    title += \"\\nrecall = {:.3f} \".format(recall)\n",
        "  if len(title) > 0:\n",
        "    ax.text(\n",
        "      101,\n",
        "      1,\n",
        "      title,\n",
        "      fontdict={\n",
        "        \"fontsize\": 18,\n",
        "        \"horizontalalignment\": \"right\",\n",
        "        \"verticalalignment\": \"top\",\n",
        "        \"color\": \"#804040\",\n",
        "      },\n",
        "    )\n",
        "  plt.show()\n",
        "\n",
        "# This function generates a confusion matrix with the model from the validation_dataset.\n",
        "def generate_confusion_matrix(model, validation_dataset, number_validation_images):\n",
        "  images_ds = validation_dataset.map(lambda image, label: image)\n",
        "  labels_ds = validation_dataset.map(lambda image, label: label).unbatch()\n",
        "\n",
        "  correct_labels = next(iter(labels_ds.batch(number_validation_images))).numpy()\n",
        "  correct_labels = np.argmax(correct_labels, axis=-1)\n",
        "  probabilities = model.predict(images_ds)\n",
        "  predictions = np.argmax(probabilities, axis=-1)\n",
        "\n",
        "  labels = range(len(CLASSES))\n",
        "  cmat = confusion_matrix(correct_labels, predictions, labels=labels)\n",
        "  cmat = (cmat.T / cmat.sum(axis=1)).T  # normalize\n",
        "\n",
        "  f1 = f1_score(correct_labels, predictions, labels=labels, average=\"macro\")\n",
        "  precision = precision_score(\n",
        "    correct_labels, predictions, labels=labels, average=\"macro\"\n",
        "  )\n",
        "  recall = recall_score(correct_labels, predictions, labels=labels, average=\"macro\")\n",
        "\n",
        "  display_confusion_matrix(cmat, f1, precision, recall)"
      ],
      "metadata": {
        "id": "Mp_X-EOQJPeH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Displaying the training curve and confusion matrix for the final model.\n",
        "display_training_curves(\n",
        "    history.history[\"acc\"],\n",
        "    history.history[\"val_acc\"],\n",
        "    \"accuracy\",\n",
        "    211,\n",
        ")\n",
        "generate_confusion_matrix(model, validation_dataset, num_validation_images)"
      ],
      "metadata": {
        "id": "EoQrrEV2J1A9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the best model with keras.\n",
        "best_model = saving.load_model('model')\n",
        "\n",
        "# Creating the test dataset.\n",
        "test_dataset = get_test_dataset(1)\n",
        "\n",
        "# Making the predictions.\n",
        "predictions = best_model.predict(test_dataset)\n",
        "\n",
        "# Calculating the number of test images in the dataset.\n",
        "num_test_images = count_data_items(TEST_FILENAMES)\n",
        "# Unbatching.\n",
        "test_ids_dataset = test_dataset.map(lambda image, idnum: idnum).unbatch()\n",
        "# Getting the image ids.\n",
        "test_ids = next(iter(test_ids_dataset.batch(num_test_images))).numpy().astype('U')\n",
        "\n",
        "# Creating the submission file.\n",
        "np.savetxt('submission.csv', np.rec.fromarrays([test_ids, predictions]), fmt=['%s', '%d'], delimiter=',', header='id,label', comments='')"
      ],
      "metadata": {
        "id": "neG_UMmyFMPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Submitting the results to kaggle.\n",
        "!kaggle competitions submit -c tpu-getting-started -f submission.csv -m 'Results'"
      ],
      "metadata": {
        "id": "kXpdI0SYHy73"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}