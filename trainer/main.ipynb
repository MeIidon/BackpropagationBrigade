{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOcEu9KysWxf+07GvRRSHmp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MeIidon/BackpropagationBrigade/blob/master/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zcM5kIyGVuYR"
      },
      "outputs": [],
      "source": [
        "import math, re, os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Tensorflow version \" + tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZPqQIYzVvdn",
        "outputId": "49635544-b6fc-4b3b-c3c2-ea11e0029228"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensorflow version 2.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Detect TPU, return appropriate distribution strategy\n",
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    print(\"Running on TPU \", tpu.master())\n",
        "except ValueError:\n",
        "    tpu = None\n",
        "\n",
        "if tpu:\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.TPUStrategy(tpu)\n",
        "else:\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "\n",
        "print(\"REPLICAS: \", strategy.num_replicas_in_sync)\n",
        "\n",
        "DATASET_PATH = \"data\"\n",
        "\n",
        "IMAGE_SIZE = [512, 512]\n",
        "PATH = DATASET_PATH + \"/tfrecords-jpeg-512x512\"\n",
        "AUTO = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "TRAINING_FILENAMES = tf.io.gfile.glob(PATH + \"/train/*.tfrec\")\n",
        "VALIDATION_FILENAMES = tf.io.gfile.glob(PATH + \"/val/*.tfrec\")\n",
        "TEST_FILENAMES = tf.io.gfile.glob(PATH + \"/test/*.tfrec\")\n",
        "\n",
        "CLASSES = [\n",
        "    \"pink primrose\",  # 0\n",
        "    \"hard-leaved pocket orchid\",  # 1\n",
        "    \"canterbury bells\",  # 2\n",
        "    \"sweet pea\",  # 3\n",
        "    \"wild geranium\",  # 4\n",
        "    \"tiger lily\",  # 5\n",
        "    \"moon orchid\",  # 6\n",
        "    \"bird of paradise\",  # 7\n",
        "    \"monkshood\",  # 8\n",
        "    \"globe thistle\",  # 9\n",
        "    \"snapdragon\",  # 10\n",
        "    \"colt's foot\",  # 11\n",
        "    \"king protea\",  # 12\n",
        "    \"spear thistle\",  # 13\n",
        "    \"yellow iris\",  # 14\n",
        "    \"globe-flower\",  # 15\n",
        "    \"purple coneflower\",  # 16\n",
        "    \"peruvian lily\",  # 17\n",
        "    \"balloon flower\",  # 18\n",
        "    \"giant white arum lily\",  # 19\n",
        "    \"fire lily\",  # 20\n",
        "    \"pincushion flower\",  # 21\n",
        "    \"fritillary\",  # 22\n",
        "    \"red ginger\",  # 23\n",
        "    \"grape hyacinth\",  # 24\n",
        "    \"corn poppy\",  # 25\n",
        "    \"prince of wales feathers\",  # 26\n",
        "    \"stemless gentian\",  # 27\n",
        "    \"artichoke\",  # 28\n",
        "    \"sweet william\",  # 29\n",
        "    \"carnation\",  # 30\n",
        "    \"garden phlox\",  # 31\n",
        "    \"love in the mist\",  # 32\n",
        "    \"cosmos\",  # 33\n",
        "    \"alpine sea holly\",  # 34\n",
        "    \"ruby-lipped cattleya\",  # 35\n",
        "    \"cape flower\",  # 36\n",
        "    \"great masterwort\",  # 37\n",
        "    \"siam tulip\",  # 38\n",
        "    \"lenten rose\",  # 39\n",
        "    \"barberton daisy\",  # 40\n",
        "    \"daffodil\",  # 41\n",
        "    \"sword lily\",  # 42\n",
        "    \"poinsettia\",  # 43\n",
        "    \"bolero deep blue\",  # 44\n",
        "    \"wallflower\",  # 45\n",
        "    \"marigold\",  # 46\n",
        "    \"buttercup\",  # 47\n",
        "    \"daisy\",  # 48\n",
        "    \"common dandelion\",  # 49\n",
        "    \"petunia\",  # 50\n",
        "    \"wild pansy\",  # 51\n",
        "    \"primula\",  # 52\n",
        "    \"sunflower\",  # 53\n",
        "    \"lilac hibiscus\",  # 54\n",
        "    \"bishop of llandaff\",  # 55\n",
        "    \"gaura\",  # 56\n",
        "    \"geranium\",  # 57\n",
        "    \"orange dahlia\",  # 58\n",
        "    \"pink-yellow dahlia\",  # 59\n",
        "    \"cautleya spicata\",  # 60\n",
        "    \"japanese anemone\",  # 61\n",
        "    \"black-eyed susan\",  # 62\n",
        "    \"silverbush\",  # 63\n",
        "    \"californian poppy\",  # 64\n",
        "    \"osteospermum\",  # 65\n",
        "    \"spring crocus\",  # 66\n",
        "    \"iris\",  # 67\n",
        "    \"windflower\",  # 68\n",
        "    \"tree poppy\",  # 69\n",
        "    \"gazania\",  # 70\n",
        "    \"azalea\",  # 71\n",
        "    \"water lily\",  # 72\n",
        "    \"rose\",  # 73\n",
        "    \"thorn apple\",  # 74\n",
        "    \"morning glory\",  # 75\n",
        "    \"passion flower\",  # 76\n",
        "    \"lotus\",  # 77\n",
        "    \"toad lily\",  # 78\n",
        "    \"anthurium\",  # 79\n",
        "    \"frangipani\",  # 80\n",
        "    \"clematis\",  # 81\n",
        "    \"hibiscus\",  # 82\n",
        "    \"columbine\",  # 83\n",
        "    \"desert-rose\",  # 84\n",
        "    \"tree mallow\",  # 85\n",
        "    \"magnolia\",  # 86\n",
        "    \"cyclamen \",  # 87\n",
        "    \"watercress\",  # 88\n",
        "    \"canna lily\",  # 89\n",
        "    \"hippeastrum \",  # 90\n",
        "    \"bee balm\",  # 91\n",
        "    \"pink quill\",  # 92\n",
        "    \"foxglove\",  # 93\n",
        "    \"bougainvillea\",  # 94\n",
        "    \"camellia\",  # 95\n",
        "    \"mallow\",  # 96\n",
        "    \"mexican petunia\",  # 97\n",
        "    \"bromelia\",  # 98\n",
        "    \"blanket flower\",  # 99\n",
        "    \"trumpet creeper\",  # 100\n",
        "    \"blackberry lily\",  # 101\n",
        "    \"common tulip\",  # 102\n",
        "    \"wild rose\",  # 103\n",
        "]\n",
        "\n",
        "\n",
        "def decode_image(image_data):\n",
        "    image = tf.image.decode_jpeg(image_data, channels=3)\n",
        "    image = (\n",
        "        tf.cast(image, tf.float32) / 255.0\n",
        "    )  # convert image to floats in [0, 1] range\n",
        "    image = tf.reshape(image, [*IMAGE_SIZE, 3])  # explicit size needed for TPU\n",
        "    return image\n",
        "\n",
        "\n",
        "def read_labelled_tfrecord(example):\n",
        "    LABELLED_TFREC_FORMAT = {\n",
        "        \"image\": tf.io.FixedLenFeature([], tf.string),  # tf.string means bytestring\n",
        "        \"class\": tf.io.FixedLenFeature([], tf.int64),  # shape [] means single element\n",
        "    }\n",
        "    example = tf.io.parse_single_example(example, LABELLED_TFREC_FORMAT)\n",
        "    image = decode_image(example[\"image\"])\n",
        "    label = tf.cast(example[\"class\"], tf.int32)\n",
        "    return image, label  # returns a dataset of (image, label) pairs\n",
        "\n",
        "\n",
        "def read_unlabelled_tfrecord(example):\n",
        "    UNLABELLED_TFREC_FORMAT = {\n",
        "        \"image\": tf.io.FixedLenFeature([], tf.string),  # tf.string means bytestring\n",
        "        \"id\": tf.io.FixedLenFeature([], tf.string),  # shape [] means single element\n",
        "        # class is missing, this competitions's challenge is to predict flower classes for the test dataset\n",
        "    }\n",
        "    example = tf.io.parse_single_example(example, UNLABELLED_TFREC_FORMAT)\n",
        "    image = decode_image(example[\"image\"])\n",
        "    id_num = example[\"id\"]\n",
        "    return image, id_num  # returns a dataset of image(s)\n",
        "\n",
        "\n",
        "def load_dataset(filenames, labelled=True, ordered=False):\n",
        "    # Read from TFRecords. For optimal performance, reading from multiple files at once and\n",
        "    # disregarding data order. Order does not matter since we will be shuffling the data anyway.\n",
        "\n",
        "    ignore_order = tf.data.Options()\n",
        "    if not ordered:\n",
        "        ignore_order.experimental_deterministic = False  # disable order, increase speed\n",
        "\n",
        "    dataset = tf.data.TFRecordDataset(\n",
        "        filenames, num_parallel_reads=AUTO\n",
        "    )  # automatically interleaves reads from multiple files\n",
        "    dataset = dataset.with_options(\n",
        "        ignore_order\n",
        "    )  # uses data as soon as it streams in, rather than in its original order\n",
        "    dataset = dataset.map(\n",
        "        read_labelled_tfrecord if labelled else read_unlabelled_tfrecord,\n",
        "        num_parallel_calls=AUTO,\n",
        "    )\n",
        "    # returns a dataset of (image, label) pairs if labelled=True or (image, id) pairs if labelled=False\n",
        "    return dataset\n",
        "\n",
        "\n",
        "def data_augment(image, label):\n",
        "    # Thanks to the dataset.prefetch(AUTO)\n",
        "    # statement in the next function (below), this happens essentially\n",
        "    # for free on TPU. Data pipeline code is executed on the \"CPU\"\n",
        "    # part of the TPU while the TPU itself is computing gradients.\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    # image = tf.image.random_saturation(image, 0, 2)\n",
        "    return image, label\n",
        "\n",
        "\n",
        "def get_training_dataset():\n",
        "    dataset = load_dataset(TRAINING_FILENAMES, labelled=True)\n",
        "    dataset = dataset.map(data_augment, num_parallel_calls=AUTO)\n",
        "    dataset = dataset.repeat()  # the training dataset must repeat for several epochs\n",
        "    dataset = dataset.shuffle(2048)\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    dataset = dataset.prefetch(\n",
        "        AUTO\n",
        "    )  # prefetch next batch while training (autotune prefetch buffer size)\n",
        "    return dataset\n",
        "\n",
        "\n",
        "def get_validation_dataset(ordered=False):\n",
        "    dataset = load_dataset(VALIDATION_FILENAMES, labelled=True, ordered=ordered)\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    dataset = dataset.cache()\n",
        "    dataset = dataset.prefetch(AUTO)\n",
        "    return dataset\n",
        "\n",
        "\n",
        "def get_test_dataset(ordered=False):\n",
        "    dataset = load_dataset(TEST_FILENAMES, labelled=False, ordered=ordered)\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    dataset = dataset.prefetch(AUTO)\n",
        "    return dataset\n",
        "\n",
        "\n",
        "def count_data_items(filenames):\n",
        "    # the number of data items is written in the name of the .tfrec\n",
        "    # files, i.e. flowers00-230.tfrec = 230 data items\n",
        "    n = [\n",
        "        int(re.compile(r\"-(\\d*)\\.\").search(filename).group(1))\n",
        "        for filename in filenames\n",
        "    ]\n",
        "    return np.sum(n)\n",
        "\n",
        "\n",
        "NUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)\n",
        "NUM_VALIDATION_IMAGES = count_data_items(VALIDATION_FILENAMES)\n",
        "NUM_TEST_IMAGES = count_data_items(TEST_FILENAMES)\n",
        "print(\n",
        "    \"Dataset: {} training images, {} validation images, {} unlabelled test images\".format(\n",
        "        NUM_TRAINING_IMAGES, NUM_VALIDATION_IMAGES, NUM_TEST_IMAGES\n",
        "    )\n",
        ")\n",
        "\n",
        "# Define the batch size. This will be 16 with TPU off and 128 (=16*8) with TPU on\n",
        "BATCH_SIZE = 16 * strategy.num_replicas_in_sync\n",
        "\n",
        "ds_train = get_training_dataset()\n",
        "ds_valid = get_validation_dataset()\n",
        "ds_test = get_test_dataset()\n",
        "\n",
        "print(\"Training:\", ds_train)\n",
        "print(\"Validation:\", ds_valid)\n",
        "print(\"Test:\", ds_test)\n",
        "\n",
        "np.set_printoptions(threshold=15, linewidth=80)\n",
        "\n",
        "print(\"Training data shapes:\")\n",
        "for image, label in ds_train.take(3):\n",
        "    print(image.numpy().shape, label.numpy().shape)\n",
        "print(\"Training data label examples:\", label.numpy())\n",
        "\n",
        "print(\"Test data shapes:\")\n",
        "for image, id_num in ds_test.take(3):\n",
        "    print(image.numpy().shape, id_num.numpy().shape)\n",
        "print(\"Test data IDs:\", id_num.numpy().astype(\"U\"))  # U=unicode string\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "def batch_to_numpy_images_and_labels(data):\n",
        "    images, labels = data\n",
        "    numpy_images = images.numpy()\n",
        "    numpy_labels = labels.numpy()\n",
        "    if numpy_labels.dtype == object:  # binary string in this case,\n",
        "        # these are image ID strings\n",
        "        numpy_labels = [None for _ in enumerate(numpy_images)]\n",
        "    # If no labels, only image IDs, return None for labels (this is\n",
        "    # the case for test data)\n",
        "    return numpy_images, numpy_labels\n",
        "\n",
        "\n",
        "def title_from_label_and_target(label, correct_label):\n",
        "    if correct_label is None:\n",
        "        return CLASSES[label], True\n",
        "    correct = label == correct_label\n",
        "    return (\n",
        "        \"{} [{}{}{}]\".format(\n",
        "            CLASSES[label],\n",
        "            \"OK\" if correct else \"NO\",\n",
        "            \"\\u2192\" if not correct else \"\",\n",
        "            CLASSES[correct_label] if not correct else \"\",\n",
        "        ),\n",
        "        correct,\n",
        "    )\n",
        "\n",
        "\n",
        "def display_one_flower(image, title, subplot, red=False, title_size=16):\n",
        "    plt.subplot(*subplot)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(image)\n",
        "    if len(title) > 0:\n",
        "        plt.title(\n",
        "            title,\n",
        "            fontsize=int(title_size) if not red else int(title_size / 1.2),\n",
        "            color=\"red\" if red else \"black\",  #\n",
        "            fontdict={\"verticalalignment\": \"center\"},\n",
        "            pad=int(title_size / 1.5),\n",
        "        )\n",
        "    return (subplot[0], subplot[1], subplot[2] + 1)\n",
        "\n",
        "\n",
        "def display_batch_of_images(data_batch, predictions=None):\n",
        "    \"\"\"This will work with:\n",
        "    display_batch_of_images(images)\n",
        "    display_batch_of_images(images, predictions)\n",
        "    display_batch_of_images((images, labels))\n",
        "    display_batch_of_images((images, labels), predictions)\n",
        "    \"\"\"\n",
        "    # data\n",
        "    images, labels = batch_to_numpy_images_and_labels(data_batch)\n",
        "    if labels is None:\n",
        "        labels = [None for _ in enumerate(images)]\n",
        "\n",
        "    # auto-squaring: this will drop data that does not fit into square\n",
        "    # or square-ish rectangle\n",
        "    rows = int(math.sqrt(len(images)))\n",
        "    cols = len(images) // rows\n",
        "\n",
        "    # size and spacing\n",
        "    FIGSIZE = 13.0\n",
        "    SPACING = 0.1\n",
        "    subplot = (rows, cols, 1)\n",
        "    if rows < cols:\n",
        "        plt.figure(figsize=(FIGSIZE, FIGSIZE / cols * rows))\n",
        "    else:\n",
        "        plt.figure(figsize=(FIGSIZE / rows * cols, FIGSIZE))\n",
        "\n",
        "    # display\n",
        "    for i, (image, label) in enumerate(\n",
        "        zip(images[: rows * cols], labels[: rows * cols])\n",
        "    ):\n",
        "        title = \"\" if label is None else CLASSES[label]\n",
        "        correct = True\n",
        "        if predictions is not None:\n",
        "            title, correct = title_from_label_and_target(predictions[i], label)\n",
        "        dynamic_title_size = (\n",
        "            FIGSIZE * SPACING / max(rows, cols) * 40 + 3\n",
        "        )  # magic formula tested to work from 1x1 to 10x10 images\n",
        "        subplot = display_one_flower(\n",
        "            image, title, subplot, not correct, title_size=dynamic_title_size\n",
        "        )\n",
        "\n",
        "    # layout\n",
        "    plt.tight_layout()\n",
        "    if label is None and predictions is None:\n",
        "        plt.subplots_adjust(wspace=0, hspace=0)\n",
        "    else:\n",
        "        plt.subplots_adjust(wspace=SPACING, hspace=SPACING)\n",
        "    plt.savefig(\"docs/flowers.png\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def display_training_curves(training, validation, title, subplot):\n",
        "    if subplot % 10 == 1:  # set up the subplots on the first call\n",
        "        plt.subplots(figsize=(10, 10), facecolor=\"#F0F0F0\")\n",
        "        plt.tight_layout()\n",
        "    ax = plt.subplot(subplot)\n",
        "    ax.set_facecolor(\"#F8F8F8\")\n",
        "    ax.plot(training)\n",
        "    ax.plot(validation)\n",
        "    ax.set_title(\"model \" + title)\n",
        "    ax.set_ylabel(title)\n",
        "    # ax.set_ylim(0.28,1.05)\n",
        "    ax.set_xlabel(\"epoch\")\n",
        "    ax.legend([\"train\", \"valid.\"])\n",
        "\n",
        "\n",
        "ds_iter = iter(ds_train.unbatch().batch(20))\n",
        "\n",
        "one_batch = next(ds_iter)\n",
        "display_batch_of_images(one_batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "9Btw_HIEWMoz",
        "outputId": "df8d053f-b347-4b46-fed0-44395c8a2590"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "REPLICAS:  1\n",
            "Dataset: 0.0 training images, 0.0 validation images, 0.0 unlabelled test images\n",
            "Training: <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 512, 512, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>\n",
            "Validation: <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 512, 512, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>\n",
            "Test: <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 512, 512, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.string, name=None))>\n",
            "Training data shapes:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-c2908a398b02>\u001b[0m in \u001b[0;36m<cell line: 261>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mds_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training data label examples:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test data shapes:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'label' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7Ytw7DQbXttR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}