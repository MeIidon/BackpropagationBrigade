{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "heSLeiKApG55",
        "outputId": "bb9b4a45-ae31-4592-c29f-65a46716d1f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.16)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ~/.kaggle\n",
        "!touch ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "tlCfhA-_s-73"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "kaggle_secret = getpass('Enter the content of your kaggle.json: ')\n",
        "\n",
        "with open('/root/.kaggle/kaggle.json', \"w\") as f:\n",
        "  f.write(kaggle_secret)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPP0_iXQqngd",
        "outputId": "de7fb747-5181-44ff-d738-3159fcb8c521"
      },
      "execution_count": 4,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the content of your kaggle.json: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c tpu-getting-started\n",
        "!unzip tpu-getting-started.zip -d data\n",
        "!rm tpu-getting-started.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nt5GbDF5sHy_",
        "outputId": "0c8b0216-d323-4346-9f0e-3ad764ca6c13"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading tpu-getting-started.zip to /content\n",
            "100% 4.79G/4.79G [02:40<00:00, 37.9MB/s]\n",
            "100% 4.79G/4.79G [02:40<00:00, 32.0MB/s]\n",
            "Archive:  tpu-getting-started.zip\n",
            "  inflating: data/sample_submission.csv  \n",
            "  inflating: data/tfrecords-jpeg-192x192/test/00-192x192-462.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-192x192/test/01-192x192-462.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-192x192/test/02-192x192-462.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-192x192/test/03-192x192-462.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-192x192/test/04-192x192-462.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-192x192/test/05-192x192-462.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-192x192/test/06-192x192-462.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-192x192/test/07-192x192-462.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-192x192/test/08-192x192-462.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-192x192/test/09-192x192-462.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-192x192/test/10-192x192-462.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-192x192/test/11-192x192-462.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-192x192/test/12-192x192-462.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-192x192/test/13-192x192-462.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-192x192/test/14-192x192-462.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-192x192/test/15-192x192-452.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-192x192/train/00-192x192-798.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-192x192/train/01-192x192-798.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-192x192/train/02-192x192-798.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-192x192/train/03-192x192-798.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-192x192/train/04-192x192-798.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-192x192/train/05-192x192-798.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-192x192/train/06-192x192-798.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-192x192/train/07-192x192-798.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-192x192/train/08-192x192-798.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-192x192/train/09-192x192-798.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-192x192/train/10-192x192-798.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-192x192/train/11-192x192-798.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-192x192/train/12-192x192-798.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-192x192/train/13-192x192-798.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-192x192/train/14-192x192-798.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-192x192/train/15-192x192-783.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-192x192/val/00-192x192-232.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-192x192/val/01-192x192-232.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-192x192/val/02-192x192-232.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-192x192/val/03-192x192-232.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-192x192/val/04-192x192-232.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-192x192/val/05-192x192-232.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-192x192/val/06-192x192-232.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-192x192/val/07-192x192-232.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-192x192/val/08-192x192-232.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-192x192/val/09-192x192-232.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-192x192/val/10-192x192-232.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-192x192/val/11-192x192-232.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-192x192/val/12-192x192-232.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-192x192/val/13-192x192-232.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-192x192/val/14-192x192-232.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-192x192/val/15-192x192-232.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-224x224/test/00-224x224-462.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-224x224/test/01-224x224-462.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-224x224/test/02-224x224-462.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-224x224/test/03-224x224-462.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-224x224/test/04-224x224-462.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-224x224/test/05-224x224-462.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-224x224/test/06-224x224-462.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-224x224/test/07-224x224-462.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-224x224/test/08-224x224-462.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-224x224/test/09-224x224-462.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-224x224/test/10-224x224-462.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-224x224/test/11-224x224-462.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-224x224/test/12-224x224-462.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-224x224/test/13-224x224-462.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-224x224/test/14-224x224-462.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-224x224/test/15-224x224-452.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-224x224/train/00-224x224-798.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-224x224/train/01-224x224-798.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-224x224/train/02-224x224-798.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-224x224/train/03-224x224-798.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-224x224/train/04-224x224-798.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-224x224/train/05-224x224-798.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-224x224/train/06-224x224-798.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-224x224/train/07-224x224-798.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-224x224/train/08-224x224-798.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-224x224/train/09-224x224-798.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-224x224/train/10-224x224-798.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-224x224/train/11-224x224-798.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-224x224/train/12-224x224-798.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-224x224/train/13-224x224-798.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-224x224/train/14-224x224-798.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-224x224/train/15-224x224-783.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-224x224/val/00-224x224-232.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-224x224/val/01-224x224-232.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-224x224/val/02-224x224-232.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-224x224/val/03-224x224-232.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-224x224/val/04-224x224-232.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-224x224/val/05-224x224-232.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-224x224/val/06-224x224-232.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-224x224/val/07-224x224-232.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-224x224/val/08-224x224-232.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-224x224/val/09-224x224-232.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-224x224/val/10-224x224-232.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-224x224/val/11-224x224-232.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-224x224/val/12-224x224-232.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-224x224/val/13-224x224-232.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-224x224/val/14-224x224-232.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-224x224/val/15-224x224-232.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-331x331/test/00-331x331-462.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-331x331/test/01-331x331-462.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-331x331/test/02-331x331-462.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-331x331/test/03-331x331-462.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-331x331/test/04-331x331-462.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-331x331/test/05-331x331-462.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-331x331/test/06-331x331-462.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-331x331/test/07-331x331-462.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-331x331/test/08-331x331-462.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-331x331/test/09-331x331-462.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-331x331/test/10-331x331-462.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-331x331/test/11-331x331-462.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-331x331/test/12-331x331-462.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-331x331/test/13-331x331-462.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-331x331/test/14-331x331-462.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-331x331/test/15-331x331-452.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-331x331/train/00-331x331-798.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-331x331/train/01-331x331-798.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-331x331/train/02-331x331-798.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-331x331/train/03-331x331-798.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-331x331/train/04-331x331-798.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-331x331/train/05-331x331-798.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-331x331/train/06-331x331-798.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-331x331/train/07-331x331-798.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-331x331/train/08-331x331-798.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-331x331/train/09-331x331-798.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-331x331/train/10-331x331-798.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-331x331/train/11-331x331-798.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-331x331/train/12-331x331-798.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-331x331/train/13-331x331-798.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-331x331/train/14-331x331-798.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-331x331/train/15-331x331-783.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-331x331/val/00-331x331-232.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-331x331/val/01-331x331-232.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-331x331/val/02-331x331-232.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-331x331/val/03-331x331-232.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-331x331/val/04-331x331-232.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-331x331/val/05-331x331-232.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-331x331/val/06-331x331-232.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-331x331/val/07-331x331-232.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-331x331/val/08-331x331-232.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-331x331/val/09-331x331-232.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-331x331/val/10-331x331-232.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-331x331/val/11-331x331-232.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-331x331/val/12-331x331-232.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-331x331/val/13-331x331-232.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-331x331/val/14-331x331-232.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-331x331/val/15-331x331-232.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-512x512/test/00-512x512-462.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-512x512/test/01-512x512-462.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-512x512/test/02-512x512-462.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-512x512/test/03-512x512-462.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-512x512/test/04-512x512-462.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-512x512/test/05-512x512-462.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-512x512/test/06-512x512-462.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-512x512/test/07-512x512-462.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-512x512/test/08-512x512-462.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-512x512/test/09-512x512-462.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-512x512/test/10-512x512-462.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-512x512/test/11-512x512-462.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-512x512/test/12-512x512-462.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-512x512/test/13-512x512-462.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-512x512/test/14-512x512-462.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-512x512/test/15-512x512-452.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-512x512/train/00-512x512-798.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-512x512/train/01-512x512-798.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-512x512/train/02-512x512-798.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-512x512/train/03-512x512-798.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-512x512/train/04-512x512-798.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-512x512/train/05-512x512-798.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-512x512/train/06-512x512-798.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-512x512/train/07-512x512-798.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-512x512/train/08-512x512-798.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-512x512/train/09-512x512-798.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-512x512/train/10-512x512-798.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-512x512/train/11-512x512-798.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-512x512/train/12-512x512-798.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-512x512/train/13-512x512-798.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-512x512/train/14-512x512-798.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-512x512/train/15-512x512-783.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-512x512/val/00-512x512-232.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-512x512/val/01-512x512-232.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-512x512/val/02-512x512-232.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-512x512/val/03-512x512-232.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-512x512/val/04-512x512-232.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-512x512/val/05-512x512-232.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-512x512/val/06-512x512-232.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-512x512/val/07-512x512-232.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-512x512/val/08-512x512-232.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-512x512/val/09-512x512-232.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-512x512/val/10-512x512-232.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-512x512/val/11-512x512-232.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-512x512/val/12-512x512-232.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-512x512/val/13-512x512-232.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-512x512/val/14-512x512-232.tfrec  \n",
            "  inflating: data/tfrecords-jpeg-512x512/val/15-512x512-232.tfrec  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "DATASET_PATH = \"data\"\n",
        "PATH = DATASET_PATH + \"/tfrecords-jpeg-512x512\"\n",
        "\n",
        "TRAINING_FILENAMES = tf.io.gfile.glob(PATH + \"/train/*.tfrec\")\n",
        "VALIDATION_FILENAMES = tf.io.gfile.glob(PATH + \"/val/*.tfrec\")\n",
        "TEST_FILENAMES = tf.io.gfile.glob(PATH + \"/test/*.tfrec\")\n",
        "\n",
        "IMAGE_SIZE = [512, 512]\n",
        "BATCH_SIZE = 32\n",
        "NUM_OF_CLASSES = 104"
      ],
      "metadata": {
        "id": "hwHaiyUWt_mz"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_image(image_data):\n",
        "  image = tf.image.decode_jpeg(image_data, channels=3)\n",
        "  image = (\n",
        "      tf.cast(image, tf.float32) / 255.0\n",
        "  )\n",
        "  image = tf.reshape(image, [*IMAGE_SIZE, 3])\n",
        "  return image\n",
        "\n",
        "\n",
        "def read_labelled_tfrecord(example):\n",
        "  LABELLED_TFREC_FORMAT = {\n",
        "    \"image\": tf.io.FixedLenFeature([], tf.string),\n",
        "    \"class\": tf.io.FixedLenFeature([], tf.int64),\n",
        "  }\n",
        "  example = tf.io.parse_single_example(example, LABELLED_TFREC_FORMAT)\n",
        "  image = decode_image(example[\"image\"])\n",
        "  label = tf.cast(example[\"class\"], tf.int32)\n",
        "  one_hot = tf.one_hot(label, NUM_OF_CLASSES)\n",
        "  return image, one_hot\n",
        "\n",
        "\n",
        "def read_unlabelled_tfrecord(example):\n",
        "  UNLABELLED_TFREC_FORMAT = {\n",
        "    \"image\": tf.io.FixedLenFeature([], tf.string),\n",
        "    \"id\": tf.io.FixedLenFeature([], tf.string),\n",
        "  }\n",
        "  example = tf.io.parse_single_example(example, UNLABELLED_TFREC_FORMAT)\n",
        "  image = decode_image(example[\"image\"])\n",
        "  id_num = example[\"id\"]\n",
        "  return image, id_num\n",
        "\n",
        "\n",
        "def load_dataset(filenames, labelled=True, ordered=False):\n",
        "  ignore_order = tf.data.Options()\n",
        "  if not ordered:\n",
        "    ignore_order.experimental_deterministic = False\n",
        "\n",
        "  dataset = tf.data.TFRecordDataset(\n",
        "    filenames, num_parallel_reads=tf.data.experimental.AUTOTUNE\n",
        "  )\n",
        "  dataset = dataset.with_options(ignore_order)\n",
        "  dataset = dataset.map(\n",
        "    read_labelled_tfrecord if labelled else read_unlabelled_tfrecord,\n",
        "    num_parallel_calls=tf.data.experimental.AUTOTUNE,\n",
        "  )\n",
        "  return dataset"
      ],
      "metadata": {
        "id": "DI-dXAxuxm9o"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_training_dataset():\n",
        "  dataset = load_dataset(TRAINING_FILENAMES, labelled=True)\n",
        "  dataset = dataset.repeat()\n",
        "  dataset = dataset.batch(BATCH_SIZE)\n",
        "  dataset = dataset.prefetch(1)\n",
        "  return dataset\n",
        "\n",
        "\n",
        "def get_validation_dataset(ordered=False):\n",
        "  dataset = load_dataset(VALIDATION_FILENAMES, labelled=True, ordered=ordered)\n",
        "  dataset = dataset.batch(BATCH_SIZE)\n",
        "  dataset = dataset.prefetch(1)\n",
        "  return dataset\n",
        "\n",
        "\n",
        "def get_test_dataset(ordered=False):\n",
        "  dataset = load_dataset(TEST_FILENAMES, labelled=False, ordered=ordered)\n",
        "  dataset = dataset.batch(BATCH_SIZE)\n",
        "  dataset = dataset.prefetch(1)\n",
        "  return dataset\n",
        "\n",
        "\n",
        "def count_data_items(filenames):\n",
        "  n = [\n",
        "      int(re.compile(r\"-(\\d*)\\.\").search(filename).group(1))\n",
        "      for filename in filenames\n",
        "  ]\n",
        "  return np.sum(n)"
      ],
      "metadata": {
        "id": "boA0dEsByty-"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_train_images = count_data_items(TRAINING_FILENAMES)\n",
        "\n",
        "train_dataset = get_training_dataset()\n",
        "validation_dataset = get_validation_dataset()\n",
        "test_dataset = get_test_dataset()"
      ],
      "metadata": {
        "id": "UQFiJq8dzhZn"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import datasets, layers, models, callbacks\n",
        "\n",
        "model = models.Sequential()\n",
        "\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu',  input_shape=(512, 512, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(16, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(104, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "\n",
        "es = callbacks.EarlyStopping(monitor='val_acc', mode='max', patience=10, verbose=1)\n",
        "cp = callbacks.ModelCheckpoint(filepath='model', save_best_only=True, verbose=1, monitor='val_acc', mode='max')\n",
        "\n",
        "model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=validation_dataset,\n",
        "    epochs=1,\n",
        "    steps_per_epoch=num_train_images / BATCH_SIZE,\n",
        "    callbacks=[es, cp]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4lKwPTy1M8t",
        "outputId": "5c868dd7-dd6b-48ad-e1e1-633199006f61"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_30\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_99 (Conv2D)          (None, 510, 510, 64)      1792      \n",
            "                                                                 \n",
            " max_pooling2d_99 (MaxPooli  (None, 255, 255, 64)      0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_100 (Conv2D)         (None, 253, 253, 32)      18464     \n",
            "                                                                 \n",
            " max_pooling2d_100 (MaxPool  (None, 126, 126, 32)      0         \n",
            " ing2D)                                                          \n",
            "                                                                 \n",
            " conv2d_101 (Conv2D)         (None, 124, 124, 16)      4624      \n",
            "                                                                 \n",
            " max_pooling2d_101 (MaxPool  (None, 62, 62, 16)        0         \n",
            " ing2D)                                                          \n",
            "                                                                 \n",
            " flatten_30 (Flatten)        (None, 61504)             0         \n",
            "                                                                 \n",
            " dense_42 (Dense)            (None, 104)               6396520   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6421400 (24.50 MB)\n",
            "Trainable params: 6421400 (24.50 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "399/398 [==============================] - ETA: 0s - loss: 3.5711 - acc: 0.1447\n",
            "Epoch 1: val_acc improved from -inf to 0.20636, saving model to model\n",
            "398/398 [==============================] - 122s 301ms/step - loss: 3.5711 - acc: 0.1447 - val_loss: 3.1775 - val_acc: 0.2064\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f4a062b2320>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    }
  ]
}